---
title: "GSoC 2017 -- A Postmortem"
date: 2017-08-14T18:36:21-06:00
---

GSoC 2017 is quickly coming to a close, and I wanted to keep a log of my decisions and
changes over the past few months in a single post. This will hopefully serve as
a component of my final submission alongside the corresponding mailing-list
threads and git commits.

For anybody that has not read my previous posts on this blog and wants to learn
more about some of the things discussed here, please read those posts and
provide me with any feedback you have.

My abstract can be found on the [GSoC website](https://summerofcode.withgoogle.com/projects/#4840095145263104)
along with all other students.

## May 2017

I began by changing some of the logic behind sample counting frame-to-frame, I
was hoping that this would make it easier to configure the psychoacoustic model
at a later time. These configuration changes have not really been made, but much
of the logic tracking the number of samples saved up has been simplified
regardless. This was done by lowering the frame size that the encoder requests
down from 1024 to 64 samples. This bank of frames are kept in a buffer queue and
pulled out when necessary.

However, this leave a couple of possible changes that are low-hanging fruit:

 * Apply LPC on any partially empty frames (most likely the last). This will
improve stability of inter-frame behavior. This was a very low priority for me
during the course of this summer, but should be an easy modification at a later
point in time.

 * Allow the user, or encoder itself, to change the delay or lookahead size for
the psychoacoustic system.

I also switched the window application to use the internal floating
point dsp module. Not only is this a more readable method, but it creates an
efficient implementation for all functions that calculate similar actions.

Relevant commit hashes and mailing list threads:

[610864dc36](https://git.io/v5kXi)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-May/211789.html)
[79941602a3](https://git.io/v5kXM)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-May/211788.html)

[25260b5161](https://git.io/v5kXQ)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-May/211791.html)
[29c13fed68](https://git.io/v5kXd)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-May/211792.html)

## June 2017

A basic psychoacoustic model was implemented. Immediate efforts went towards
adapting the Vorbis encoder to function with the AAC psychoacoustic system
already present in FFmpeg. This work would have unfortunately lead to additional
code that was quite unreadable, and I recognized that applying the AAC model to
Vorbis would be fairly inappropriate as each codec is based on fundamentally
different bases.

I decided that I would roll out a model specific to Vorbis so that
characteristic qualities of Vorbis could be utilized more fully, and duplicated
effort would be minimized. I unfortunately spent a significant portion of this
first month trying to force the Vorbis encoder to accommodate the AAC model,
and I was unable to design the transient detector in the fashion that I may have
wanted to.

As a result of the time crunch, I ended up following a fairly basic approach to
detecting transient signals. The
brief explanation is approaching this classification as a matter of statistic
variation of a filtered input signal in comparison to previous blocks.
Surprisingly, this approach had decent accuracy considering how simple its
implementation was.

This was a moment of some unique challenges for me. Before this point, I had no
understanding of digital signal processing. I was facing an intersection between
two fields that have fairly challenging domain-specific knowledge. While there
is some overlap in these areas, I was a bit overwhelmed at first. Despite this,
I believe that the code ended simple and clear enough to understand while still
leaving further opportunities to upgrade to a more mature system.

Most recent mailing list threads of the relevant commits:

(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215108.html)
(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215111.html)

## July 2017

The first couple of weeks during this portion was spent struggling to debug the
code I had recently introduced. I mistakenly tried to maintain style consistency
with preexisting portions of the coder with respect to pointer arithmetic in
arrays. This led to some code that was very unreadable and masked obvious errors.

After these changes had been made. Atomnuker, my mentor, had noticed some
artifacts that become very distracting at low bitrates (~35 KBps/channel).
Initial thoughts were that it was caused by a lack of stability. I *was*
concerned about stability, but I still didn't think it was the cause of this
clicking. After further discussion, he had suggested that it was a matter of a
lack of bitrate management. I'm still not fully convinced that this is the
issue. As a hotfix, I decided to implement simple clipping avoidance similar to
how it works with AAC's system. This worked relatively well for normal quality
values, but still didn't fix the problem at low bitrates.

While wrangling with the above issues, I began implementing different channel
mappings. Channel configurations were implemented in a strict stereo-only mode
in the coder. As a result, many assumptions were made throughout the encoder
that relied on only two channels being present. I spent some time removing some
of these *magic* values, and restructured how residues and floors were
configured.

This was a bit overkill for support for mono streams, but was necessary for any
work to be done with configurations that had more than one coupling step or
introduced an LFE channel. Unfortunately, channel configurations past 2 channel
stereo were never added, but minimal changes need to be made to accept those.

During this period I also began researching how noise normalization and shaping
is implemented within Vorbis. Noise shaping will not be implemented with this
GSoC project, but much of the code has been written for it, and a post
discussing it should be available soon(TM).

Most recent mailing list threads of the relevant commits:

(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215106.html)
(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215110.html)

(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215107.html)
(Still pending)--[ML](http://ffmpeg.org/pipermail/ffmpeg-devel/2017-August/215109.html)

## August 2017

The home stretch! During this final period I wanted to work on some of the core
components of the Vorbis encoder that would allow much of the remaining work to
be done without requiring any major changes to the code. I had initially wanted
to work on implementing better bit-rate control but quickly realized that there
was a large amount of foundational work that needed to be done. I recognized a
few basic changes that needed to be done before advanced features could be
implemented:

The first necessary implementation was noise normalization. I talk about it more
in-depth in a previous. This essentially corrects for a loss of energy caused by
quantization of the floor curve. Manipulation of quantized floor values is a
technique used in later psychoacoustic and bit-rate control methods in the
reference implementation.

Proper stereo coupling is our second avenue. The native encoder already uses
channel interleaving for residue construction which provides decent lossless
savings, but only primitive coupling was used otherwise. Monty from Xiph.org has
some [great](https://people.xiph.org/~xiphmont/demo/surround/demo.html)
[resources](https://xiph.org/vorbis/doc/stereo.html) on stereo coupling. The
stereo coupling in the native encoder will act similar to the libvorbis
implementation, coupling differently based on frequency level and how easily
humans can perceive incorrect phase. This allows more aggressive compression
while limiting the perceivable impact.

Looking back towards the beginning of the year, I realized that a large barrier
for entry for me was the lack of documentation throughout the Vorbis encoder.
From a technical perspective, the version of the encoder that existed before my
work was fairly simple, but only for someone with previous A/V experience. The
reference encoder suffers from the same problem.

I prioritized writing clear code throughout the summer, but decided that more
documentation was still needed. At this time, I decided to try documenting any
code that I struggled with back in February, even if it seems trivial now. A/V
encoding already seems like a dark art to anybody unfamiliar with it,
documentation should err on the side of verbosity instead of brevity in order to
help counter balance it rather than exacerbate it.

## Work in Progress

Following below are the major components of the vorbis encoder that are
currently in progress and will be completed after the end of GSoC 2017:

 * Modification of the residue encoding is still being worked on. Accurate
   quantization values have already been obtained, and noise normalization works
   as expected. However, the residue encoder expects coupled MDCT output
   rather than quantized values and must be adapted to work.

 * Improved stereo coupling is also a work in progress. This has the potential
   to contribute considerable savings to the output audio stream. More fine tuning
   of thresholds for different coupling schemes needs to be done.

## Future Goals

This GSoC project has laid significant groundwork for future improvements in
FFmpeg's native Vorbis encoder. In addition to the options posed above, some
possible areas of technical improvement include:

 * Greater bitrate control. I consider this a fairly weak spot in the libvorbis
   implementation. There are significant opportunities to implement high-impact
   techniques here. I was not able to find a decent answer to this problem beyond
   the fairly simple iterative technique used by libvorbis.

 * Further psychoacoustic analysis. Any possible psychoacoustic model now has a
   much greater amount of information available to make decisions. I've added
   proper energy tracking via noise normalization and output quantization values
   are available for fine-grained control.

 * More dynamic coupling mechanisms. Monty from Xiph.org has discussed stereo
   coupling in great depth on his blog posts. Possibilities include implementing
   proper 8-phase stereo and highly-compressed lossless coupling. These two
   components can lower the bit-rate requirement for perceptually lossless
   coupling.

 * Quality control mechanisms. Many codecs will respect quality levels passed
   in by the user. The current encoder does not use quality levels in an
   intelligent way, but options that can be configured for different quality
   levels have been documented for future work.

More user-facing changes could include preserving the metadata when encoding a
file, (i.e. Album, Artist, Track, Genre, etc.)

Additionally, there is room to better integrate the code written this summer
with the larger FFmpeg source code by generalizing  the psychoacoustic code to
work with any other audio codecs that wish to follow the same model. I had
initially written all psychoacoustic code with data types local to the Vorbis
encoder.

## Final Remarks

When applying to GSoC, I was unfamiliar with A/V coding as a whole, and the code
bases in question (FFmpeg and libvorbis). I didn't realize the difficulty I
would have trying to follow the undocumented native encoder, or the libvorbis
implementation that has been relatively forgotten. As a result, I did not
achieve everything that I initially proposed in my application. However, I'm
glad my work turned in a different direction as I feel that the changes made
this summer make more sense for FFmpeg's native Vorbis encoder in the long term.

I wanted to end with appreciation for atomnuker and the others in FFmpeg that
provided assistance during this summer. The folks that work on this project are
incredibly talented, and I learned so much. This was a great opportunity to
improve my development skills while producing something that has value for the
FOSS community.
